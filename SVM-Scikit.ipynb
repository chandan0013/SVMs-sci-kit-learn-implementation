{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fname = ('C:/Users/Chandan/Documents/CPTS 570/Homework/HW 2/data/fashion-mnist_train.csv')\n",
    "data_train = np.loadtxt(fname, delimiter = ',', skiprows = 1)\n",
    "\n",
    "\n",
    "fname = ('C:/Users/Chandan/Documents/CPTS 570/Homework/HW 2/data/fashion-mnist_test.csv')\n",
    "data_test = np.loadtxt(fname, delimiter = ',', skiprows = 1)\n",
    "\n",
    "X_train = data_train[0:48000,1:]\n",
    "X_validation = data_train[48000:60000,1:]\n",
    "X_test = data_test[:,1:]\n",
    "X_combined = data_train[:,1:]\n",
    "\n",
    "Y_train = data_train[0:48000,0]\n",
    "Y_validation = data_train[48000:60000,0]\n",
    "Y_test = data_test[:,0]   \n",
    "Y_combined = data_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1 a Accuracy plot for Training, Testinng and Validation Data as function of C\n",
    "\n",
    "Training_acc = []\n",
    "Validation_acc = []\n",
    "Test_acc = []\n",
    "axis = (1 , 2 , 3 , 4, 5, 6, 7, 8, 9)\n",
    "x_axis = (0.0001 ,0.001 ,0.01 ,0.1 , 1 ,10 ,100 ,1000 ,10000)\n",
    "\n",
    "for c in range(9):\n",
    "    lin_clf = svm.LinearSVC(C = x_axis[c])\n",
    "    lin_clf.fit(X_train, Y_train) \n",
    "    \n",
    "    # No SVM vectors function for linear kernels\n",
    "\n",
    "    # Now I have the functional for prediction\n",
    "    count = 0\n",
    "    for i in range(48000):\n",
    "        y = lin_clf.predict([X_train[i,:]])\n",
    "        if y != Y_train[i]:\n",
    "            count = count + 1 \n",
    "    Training_acc.append((48000-count)/48000)     \n",
    "\n",
    "    count = 0\n",
    "    for ii in range(12000):\n",
    "        y = lin_clf.predict([X_validation[ii,:]])\n",
    "        if y != Y_validation[ii]:\n",
    "            count = count + 1 \n",
    "    Validation_acc.append((12000-count)/12000) \n",
    "\n",
    "    count = 0\n",
    "    for iii in range(10000):\n",
    "        y = lin_clf.predict([X_test[iii,:]])\n",
    "        if y != Y_test[iii]:\n",
    "            count = count + 1 \n",
    "    Test_acc.append((10000-count)/10000)  \n",
    "    \n",
    "plt.plot(axis,Training_acc , 'r--', axis, Validation_acc, 'bs--', axis, Test_acc, 'g^--')\n",
    "plt.xlabel('Different values of C as specified in question')\n",
    "plt.ylabel('Accuracy Plot for 9 increments')\n",
    "plt.legend(('Training', 'Validation', 'Test'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1b testing accuracy and confusion matrix of linear kernel SVM\n",
    "\n",
    "#Confusion matrix\n",
    "# Create array of Y and Y predicted\n",
    "lin_clf = svm.LinearSVC(C = x_axis[np.argmax(Test_acc)])\n",
    "lin_clf.fit(X_combined, Y_combined) \n",
    "# No SVM vectors function for linear kernels\n",
    "Combined_Test_acc = []          # Testing Accuracy for combined Training X\n",
    "Training_Y = []                 # Array of predicted Y from training X\n",
    "Validation_Y = []               # Array of predicted Y from Validation X\n",
    "Test_Y = []                     # Array of predicted Y from test X\n",
    "# Now I have the functional for prediction\n",
    "\n",
    "for i in range(48000):\n",
    "    y = lin_clf.predict([X_train[i,:]])\n",
    "    Training_Y.append(y)     \n",
    "\n",
    "count = 0\n",
    "for ii in range(12000):\n",
    "    y = lin_clf.predict([X_validation[ii,:]])\n",
    "    Validation_Y.append(y) \n",
    "\n",
    "count = 0\n",
    "for iii in range(10000):\n",
    "    y = lin_clf.predict([X_test[iii,:]])\n",
    "    Test_Y.append(y)\n",
    "    \n",
    "count = 0\n",
    "for iii in range(10000):\n",
    "    y = lin_clf.predict([X_test[iii,:]])\n",
    "    if y != Y_test[iii]:\n",
    "         count = count + 1 \n",
    "Combined_Test_acc.append((10000-count)/10000)\n",
    "    \n",
    "Confusion_Training = confusion_matrix(Y_train, Training_Y)    # Training Confusion matrix\n",
    "print('Training Confusion Matrix is: \\n',Confusion_Training)        \n",
    "\n",
    "Confusion_Validation = confusion_matrix(Y_validation, Validation_Y)    # Validation Confusion matrix\n",
    "print('Validation Confusion Matrix is: \\n',Confusion_Validation)\n",
    "\n",
    "Confusion_Test = confusion_matrix(Y_test, Test_Y)                      # Test Confusion matrix\n",
    "print('Test Confusion Matrix is: \\n',Confusion_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1c Number of support vectors for each polynomial degree\n",
    "Poly_axis = (1, 2 , 3 , 4)\n",
    "x =[]\n",
    "for c in range(4):\n",
    "    clf = svm.SVC(C = x_axis[np.argmax(Test_acc)], degree = Poly_axis[c], kernel = 'poly')\n",
    "    clf.fit(X_train, Y_train) \n",
    "    clf.support_vectors_\n",
    "    x.append(len(clf.support_vectors_))\n",
    "    \n",
    "plt.plot(Poly_axis,x , 'r')\n",
    "plt.xlabel('Different Degree Value')\n",
    "plt.ylabel('Support vectors for polynomial kernels')\n",
    "plt.legend(('# of Support vectors'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1c Accuracy curve for polynomial degrees\n",
    "Poly_Training_acc = []\n",
    "Poly_Validation_acc = []\n",
    "Poly_Test_acc = []\n",
    "Poly_axis = (1, 2 , 3 , 4)\n",
    "for c in range(4):\n",
    "    clf = svm.SVC(C = x_axis[np.argmax(Test_acc)], degree = Poly_axis[c], kernel = 'poly')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # No SVM vectors function for linear kernels\n",
    "\n",
    "    # Now I have the functional for prediction\n",
    "    count = 0\n",
    "    for i in range(48000):\n",
    "        y = clf.predict([X_train[i,:]])\n",
    "        if y != Y_train[i]:\n",
    "            count = count + 1 \n",
    "    Poly_Training_acc.append((48000-count)/48000)     \n",
    "\n",
    "    count = 0\n",
    "    for ii in range(12000):\n",
    "        y = clf.predict([X_validation[ii,:]])\n",
    "        if y != Y_validation[ii]:\n",
    "            count = count + 1 \n",
    "    Poly_Validation_acc.append((12000-count)/12000) \n",
    "\n",
    "    count = 0\n",
    "    for iii in range(10000):\n",
    "        y = clf.predict([X_test[iii,:]])\n",
    "        if y != Y_test[iii]:\n",
    "            count = count + 1 \n",
    "    Poly_Test_acc.append((10000-count)/10000)  \n",
    "    \n",
    "plt.plot(Poly_axis,Poly_Training_acc , 'r--', Poly_axis, Poly_Validation_acc, 'bs--', Poly_axis, Poly_Test_acc, 'g^--')\n",
    "plt.xlabel('Different Degree Value')\n",
    "plt.ylabel('Accuracy Plot for polynomial kernels')\n",
    "plt.legend(('Training', 'Validation', 'Test'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel defination k = (x.y + 1)^polynomial\n",
    "# First Calculate the Kernel matrix for MC\n",
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "X_train = scaling.transform(X_train)\n",
    "X_test = scaling.transform(X_test)\n",
    "X_validation = scaling.transform(X_validation)\n",
    "\n",
    "t = (10,48000)\n",
    "Alpha = np.zeros(t)\n",
    "mistakes = []\n",
    "axis = (1, 2,3,4,5) \n",
    "for itr in range(5):\n",
    "    count = 0\n",
    "    print('mistakes',mistakes)\n",
    "    for i in range(48000):\n",
    "        x = X_train[i,:]\n",
    "        row_sum = 0\n",
    "        score = []      #Representation 2\n",
    "        for r in range(10):   #10 classes\n",
    "            for j in range(48000):#60,000 examples\n",
    "                row_sum = row_sum + Alpha[r,j]*((np.dot(x,X_train[j,:]) + 1)**2)\n",
    "            score.append(row_sum)\n",
    "                \n",
    "        y_pred = np.argmax(score)\n",
    "        if y_pred != Y_train[i]:\n",
    "            c = Y_train[i]\n",
    "            Alpha[ c.astype(int),i] = Alpha[c.astype(int),i] + 1\n",
    "            Alpha[y_pred,i] = Alpha[y_pred,i] - 1\n",
    "            count = count + 1  \n",
    " \n",
    "    mistakes.append(count) \n",
    "\n",
    "\n",
    "plt.plot(axis,mistakes , 'r--')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Mistakes')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Kernel_Training_acc = []\n",
    "Kernel_Validation_acc = []\n",
    "Kernel_Test_acc = []\n",
    "\n",
    "# Alpha_matrix is crteated, but the kernel matrix is still required for predicting\n",
    "\n",
    "count = 0\n",
    "for i in range(10000):\n",
    "    x = X_test[i,:]\n",
    "    row_sum = 0\n",
    "    score = []      #Representation 2\n",
    "    for r in range(10):\n",
    "        for j in range(60000):\n",
    "            row_sum = row_sum + Alpha[r,j]*(np.dot(x,X_combined[j,:]) + 1)\n",
    "        score.append(row_sum)\n",
    "        \n",
    "    y_pred = np.argmax(score)\n",
    "    if y_pred != Y_train[i]:\n",
    "        count = count+1\n",
    "    \n",
    "Kernel_Test_acc.append((10000-count)/10000)  \n",
    "print('Test accuracy is: \\n',Kernel_Test_acc)\n",
    "\n",
    "count = 0\n",
    "for i in range(12000):\n",
    "    x = X_validation[i,:]\n",
    "    row_sum = 0\n",
    "    score = []      #Representation 2\n",
    "    for r in range(10):\n",
    "        for j in range(60000):\n",
    "            row_sum = row_sum + Alpha[r,j]*((np.dot(x,X_combined[j,:]) + 1)**2)\n",
    "        score.append(row_sum)\n",
    "        \n",
    "    y_pred = np.argmax(score)\n",
    "    if y_pred != Y_train[i]:\n",
    "        count = count+1\n",
    "    \n",
    "Kernel_Validation_acc.append((12000-count)/12000)  \n",
    "print('Training accuracy is: \\n',Kernel_Validation_acc)\n",
    "\n",
    "count = 0\n",
    "for i in range(48000):\n",
    "    x = X_train[i,:]\n",
    "    row_sum = 0\n",
    "    score = []      #Representation 2\n",
    "    for r in range(10):\n",
    "        for j in range(48000):\n",
    "            row_sum = row_sum + Alpha[r,j]*((np.dot(x,X_train[j,:]) + 1)**2)\n",
    "        score.append(row_sum)\n",
    "        \n",
    "    y_pred = np.argmax(score)\n",
    "    if y_pred != Y_train[i]:\n",
    "        count = count+1\n",
    "    \n",
    "Kernel_Training_acc.append((48000-count)/48000)    \n",
    "print('Training accuracy is: \\n',Kernel_Training_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
